# big-data-wrangling-google-ngrams
Distributed data pipeline using AWS EMR, Spark, HDFS, and S3 to process Google Books Ngrams. Includes ingest, filtering, and export workflows, Jupyter notebooks for PySpark + pandas analysis, and a full LaTeX report comparing Hadoop vs. Spark and documenting results
